# üì∞ | Plataforma de Not√≠cias de Sa√∫de

---

<img src="assets/header.png">


*"Solu√ß√£o Event Driven com Airflow e aplica√ß√£o de Rag com Snowflake"*.


<h2>Sum√°rio</h2>
<hr>

- [0. Problema de Neg√≥cio](#0-problema-de-neg√≥cio)
- [1. Estrat√©gia de Solu√ß√£o](#1-estrat√©gia-de-solu√ß√£o)
- [2. Ingest√£o de Dados](#2-ingest√£o-de-dados)
  - [2.1. Scraping de Not√≠cias](#21-scraping-de-not√≠cias)
  - [2.2. Event Driven Dag](#22-Event-Driven-Dag) 
- [3. Processamento de Dados](#3-processamento-de-dados)
- [4. Rag com Snowflake](#4-rag-com-snowflake)

<hr>

<h2>0. Problema de Neg√≥cio</h2>
<hr>

O principal problema enfrentado atualmente √© a falta de acesso confi√°vel a eventos realizados em rela√ß√£o a sa√∫de p√∫blica no Brasil, muitas fam√≠lias se √© que sabem que esta tendo algum evento de conscientiza√ß√£o, vacina√ß√£o ou qualquer outro meio ou solu√ß√£o proposta pelo sistema de sa√∫de da cidade em sua vizinhan√ßa devido a falta de tempo ou demais caracter√≠sticas que impedem essas fam√≠lias de obter essas informa√ß√µes de maneira f√°cil e simples.   

O ge√≥grafo brasileiro Milton Santos, descreve em seu c√©lebre texto "As Cidadanias Mutiladas" que a democracia somente √© efetiva quando atinge todo o corpo social, isto √©, quando os direitos s√£o desfrutados por todos os cidad√£os. Todavia, no contexto atual brasileiro, diante dos desafios ao acesso a uma plataforma de noticias de sa√∫de p√∫blica, distanciam a popula√ß√£o de direitos a not√≠cias que todos deveriam ter acesso de uma forma simples e eficiente. Neste contexto, faz-se necess√°rio a solu√ß√£o dos desafios para implementar uma plataforma de not√≠cias de sa√∫de p√∫blica que seja acess√≠vel a todos os brasileiros.

Em primeiro lugar vale a pena ressaltar a desinforma√ß√£o populacional como um dos principais fatores que corroboram para a persist√™ncia do problema no que tange o tema plataforma de sa√∫de p√∫blica Brasil. Durante a formaliza√ß√£o do atual plano educacional proposto na era Vargas no s√©culo XX √© poss√≠vel observer a falta de conte√∫do na ementa envolvendo temas transversais, como a sa√∫de, direitos e tecnologia. Nesta perspectiva, muitos brasileiros n√£o conhecem os seus direitos relacionados a sa√∫de p√∫blica e n√£o possuem experi√™ncia para utilizar ferramentas tecnol√≥gicas para encontrar informa√ß√µes relevantes sobre not√≠cias desta tem√°tica. Diante disso, muitas pessoas n√£o possuem os insumos necess√°rios e precisam de uma plataforma de n√≥ticias confi√°vel para consultar no dia a dia.    

<h2>1. Estrat√©gia de Solu√ß√£o</h2>
<hr>

O projeto teve in√≠cio com uma etapa de imers√£o no problema de neg√≥cios, buscando compreender os desafios e as necessidades dos usu√°rios finais. A partir desse entendimento, foi realizado um planejamento detalhado das atividades que orientariam o desenvolvimento da solu√ß√£o. A solu√ß√£o proposta √© baseada em uma arquitetura orientada a eventos (Event-Driven Architecture) e com essa arquitetura seu principal objetivo √© facilitar o acesso a informa√ß√µes cr√≠ticas na √°rea de Sa√∫de das cidades de santa catarina, inicialmente com amostras dacidade de Ca√ßador.
Como as novas publica√ß√µes de not√≠cias de sa√∫de em fontes oficiais de dados (por exemplo, SUS, portais do governo, entre outros) s√£o gerados em tempos intermitentes √© necess√°rio metodologias por meio de um fluxo moderno e eficiente de ingest√£o e processamento de dados. Al√©m disso a disponibiliza√ß√£o desses dados a os usu√°rios finais deve ser por meio de linguagem natural.

- Gera√ß√£o de eventos: Not√≠cias e atualiza√ß√µes s√£o publicadas periodicamente por fontes oficiais.
- Ingest√£o de dados: Esses eventos s√£o capturados de forma ass√≠ncrona por mecanismos Event-Driven.
- Processamento: Os dados s√£o tratados dentro de uma arquitetura moderna de Engenharia de Dados em camadas de consumo (Lakehouse), que combina as vantagens dos data warehouses com a flexibilidade dos data lakes.
- Utiliza√ß√£o de t√©cnicas de RAG (Retrieval-Augmented Generation): Interface em linguagem natural, que permite a usu√°rios com pouco ou nenhum conhecimento t√©cnico acessar e interpretar os dados com facilidade.
- Workflow: Automa√ß√£o e escalabilidade no fluxo de dados.
- Inclus√£o Digital: Acessibilidade da informa√ß√£o para p√∫blicos diversos.
- Confiabilidade: Velocidade na tomada de decis√£o, com dados sempre atualizados.

<img src="assets/workflow.png">

Toda a solu√ß√£o de infraestrutura foi desenvolvida com Terraform integrado a AWS + Snowflake, al√©m disso com a utiliza√ß√£o do Python, Airflow, DBT e Snowflake Warehouse para as ferramentas de processamento, orquestra√ß√£o e documenta√ß√£o, por fim o Snowflake Cortex Service para a camada de PLN, VectorDB e RAG com Langchain e SQL. 

<h2>2. Ingest√£o de Dados</h2>
<hr>

<h3>2.1. Scraping de Not√≠cias</h3>

A primeira etapa da solu√ß√£o foi o desenvolvimento dos `crawlers`, isto √©, o desenvolvimento das aplica√ß√µes respons√°veis pela raspagem dos dados de sites de not√≠cias, a principal fonte de dados utilizada foi o site de not√≠cias da Secretaria de Sa√∫de da cidade de Ca√ßador, Santa Catarina, esse site √© um portal de not√≠cias relacionadas a Sa√∫de P√∫blica que s√£o pertinentes a toda a popula√ß√£o da cidade de Ca√ßador.

Como este projeto est√° totalmente p√∫blico, sem fins lucrativos e relacionado a estudos, optei em utilizar o site de Ca√ßador inicialmente para os primeiros testes, al√©m disso o site possui o robotx.txt limitando alguns endpoints que n√£o estou raspando, ent√£o o projeto n√£o infringe nenhuma regra do site at√© o momento em que esse projeto foi desenvolvido.

Os `crawlers` s√£o executados em tempos intermitentes, ou seja, apareceu uma not√≠cia nova, em algum momento o crawler vai ser executado e coletar essa not√≠cia e armazenar o texto bruto e outros metadados em arquivos no armazenamento de arquivos da Aws, esse armazenamento foi nomeado de Data Lake e esses arquivos s√£o particionados por data na primeira camada do Data Lake chamada de Landing.

<img src="assets/aws_sqs_queue.png">

Quando um novo arquivo chega nesta camada landing, √© disparado um indicativo por meio do `AWS SQS` para a pr√≥xima ferramenta da arquitetura, o `Airflow`.

<h3>2.2. Event Driven Dag</h3>

O `Airflow` vai ficar aguardando alguma nova mensagem recebida por meio do AWS SQS, caso o `Airflow` receba essa nova mensagem ele vai ser executado e orquestrar o workflow e subsequentemente a respectiva dag com as devidas tasks.

<img src="assets/airflow_dagrun_asset_trigger.png">

<img src="assets/airflow_asset.png">

Essa funcionalidade desbloqueia um pipeline baseado em eventos, ou seja, a cada nova not√≠cia √© executado o `Airflow`, o `airflow` √© a ferramenta respons√°vel por executar o projeto DBT que por sua vez vai fazer a atualiza√ß√£o das tabelas no Snowflake.

<h2>3. Processamento de Dados</h2>
<hr>

A camada de processamento dos dados √© a segunda etapa da solu√ß√£o.

Quando o `Airflow` √© executado, o mesmo dispara consultas SQL por meio do DBT, em outras palavras, o `Airflow` vai executar consultas SQL, chamadas de fun√ß√µes e execu√ß√£o de procedures na plataforma do Snowflake por meio de um Compute Warehouse.

Os dados dentro da plataforma do Snowflake s√£o nomeados de objetos, esses objetos possuem uma forte pol√≠tica de controle de acesso e tamb√©m toda a infraestrutura do Snowflake foi levantada por meio do Terraform com m√≥dulos que j√° est√£o em preview no terraform atualmente.

Esses objetos dentro do Snowflake, alguns deles s√£o tabelas, essas tabelas seguem a modelagem de Lakehouse, as tabelas s√£o organizadas em camadas, Bronze, Silver e Gold.

- Bronze: Os dados s√£o coletados e escritos de forma hist√≥rica nesta tabela, particionado por data, essa escrita √© realizada por meio de um Python Procedure.
- Silver: Os dados da camada bronze s√£o ent√£o processados e atualizados em tabelas "silvers".
- Gold: Os dados j√° limpos da camada silver s√£o ent√£o agregados em vis√µes anal√≠ticas ou enviesadas para alguma faceta de neg√≥cio.

Seguindo a perspectiva anterior, a tabela Gold utilizada no `Cortex Service`, ou seja, a tabela enviesada para o neg√≥cio utilizar como Vector Database esta na camada Gold, √© uma tabela processada onde as not√≠cias s√£o quebradas em chunks para a recupera√ß√£o depois, conforme ilustra a imagem abaixo.

<img src="assets/snowflake_noticias_chunk_table.png">


<h2>4. Rag com Snowflake</h2>
<hr>

A √∫ltima etapa do projeto √© justamente a elabora√ß√£o da plataforma de not√≠cias de sa√∫de, para isso foi utilizado o `Cortex Service` do Snowflake, infelizmente essa solu√ß√£o ainda esta em testes no terraform, ent√£o ela foi levantada manualmente utilizando o Snowsight.

A solu√ß√£o do `Cortex Service` permite ao usu√°rio selecionaer um LLM para ser a ferramenta de gera√ß√£o de embeddings que j√° esta integrada a tabelas da camada Gold, isto √©, o proprio `Cortex Service` faz a atualiza√ß√£o dos embeddings e nos permite disparar perguntas utilizando linguagem natural facilitando a busca e pesquisa de not√≠cias de sa√∫de p√∫blica da cidade de Ca√ßador, Santa Catarina.

Por exemplo, considere a seguinte pergunta enviada ao `Cortex Service`: "Qual foi o custo em reais de materiais para a pr√°tica de artes marciais ?".

A coluna GEN da imagem abaixo nada mais √© que a resposta da pergunta utilizando pesquisa vetorial e a gera√ß√£o de texto do LLM selecionado dentro da plataforma do `Cortex Service` do Snowflake.

<img src="assets/snowflake_rag_sql.png">

Dessa forma √© poss√≠vel pessoas leigas realizarem perguntas relacionados a tem√°tica de sa√∫de dentro da plataforma e obterem as devidas respostas. 

